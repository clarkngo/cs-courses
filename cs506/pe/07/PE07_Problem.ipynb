{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695d9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a10cdd",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Problem 1: Understanding of a classifier**\n",
    "---\n",
    "\n",
    " Write a program such that different training variables such as max depth for DecisionTreeClassifier and \"k\" for KNN classifier \n",
    " can have consecutive values being experimented. For example, rewrite the\n",
    " following code so that mxdepth starts from 1 to 10 or k goes from 1 to 10\n",
    " You will need to plot the accuracy per varying these parameters of each classifier \n",
    " with your analysis in words\n",
    "\n",
    "---\n",
    "\n",
    " Resource:\n",
    " [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    " A decision tree classifier. Training parameter is mxdepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf78cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Iris Dataset\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "# split the data into split ratio for training set and (1.0-split) for testing set.\n",
    "# i.e. 0.9 means 90% of the data set is dedicated for training while 10% is dedicated for testing\n",
    "split = 0.9\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32eee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC (1) = 0.66 accuracy\n"
     ]
    }
   ],
   "source": [
    "mxdepth = 1 # vary this mxdepth from 1 to 10 and identify which mxdepth provides you the best result and plot the accuracy of those 10 results.\n",
    "DTclassifier = DecisionTreeClassifier(max_depth=mxdepth)\n",
    "DTclassifier.fit(x_train,y_train)\n",
    "predictions=DTclassifier.predict(x_test)\n",
    "print(f\"DTC ({mxdepth}) = %0.2f accuracy\" % accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24829b40",
   "metadata": {},
   "source": [
    "Resource: [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) Finds the K-neighbors of a point. Returns indices of and distances to the neighbors of each point.\n",
    " Training parameter is k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f4674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (1) = 0.95 accuracy\n"
     ]
    }
   ],
   "source": [
    "k = 1 # vary this k from 1 to 10 and identify which mxdepth provides you the best result and plot the accuracy of those 10 results.\n",
    "KNNclassifier = KNeighborsClassifier(n_neighbors=k)\n",
    "KNNclassifier.fit(x_train,y_train)\n",
    "predictions=KNNclassifier.predict(x_test)\n",
    "print(f\"KNN ({k}) = %0.2f accuracy\" % accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b002b30",
   "metadata": {},
   "source": [
    "#### Problem #1 Summary\n",
    "---\n",
    "Provide your summary for the problem #1 here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c72cf9",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Problem 2: Feature Selection** \n",
    "---\n",
    "Problem 2: The data contains 4 different features namely sepal length, sepal width, petal length, and petal width\n",
    "It is important to recognize which feature set(s) performs the best. Choose the best combination based on your\n",
    "experiment. You will have 10 different combinations possible (e.g. {SL, SW, PL, PW, (SL,SW), (SL, PL)...(SL, SW, PL, PW)} \n",
    "You will show different performance after based on the best training parameters from Problem #1.\n",
    "This may show that the more number of features doesn't end up with better accuracy necessarily. \n",
    "You will have the performance results per 10 combinations and plot the results on a graph for each classifier. Provide your analysis.\n",
    "\n",
    "Refer to the topic in the \"curse of dimensionality\" below.\n",
    " Resource:\n",
    " [Curse of Dimensionality](Resource : https://en.wikipedia.org/wiki/Curse_of_dimensionality)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189c005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names\n",
    "feature_names = iris.feature_names\n",
    "feature_names\n",
    "\n",
    "#\n",
    "# Generate 10 combination from those 4 features\n",
    "#\n",
    "# Apply those features on both DTC and KCC\n",
    "#\n",
    "# Do you observe the curse of dimensionality issue?\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456b089",
   "metadata": {},
   "source": [
    "#### Problem #2 Summary\n",
    "---\n",
    "Provide your summary for the problem #2 here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4619b",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Problem 3: Putting it all together**\n",
    "---\n",
    "Problem 3: Once you decide the best feature set(s) from the Problem #2, it is important to recognize how the size of training set versus testing set (or ratio between sets) would influence the overall representative performance. You will have the performance results based on different split ratio. Plot the results on a graph for each classifier applying the best parameters so far and provide your analysis in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8df565",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.1 # vary the split ratio from 0.1 to 0.9\n",
    "x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=split)\n",
    "\n",
    "#\n",
    "# Find the best feature(s) given the current split ratio while fixing mxdepth and K values from problem #1\n",
    "# \n",
    "# Compare the performance results by the two classifiers at split = 0.1, 0.2 ... 0.9\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80b584",
   "metadata": {},
   "source": [
    "#### Problem #3 Summary\n",
    "---\n",
    "Provide your summary for the problem #3 here \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
