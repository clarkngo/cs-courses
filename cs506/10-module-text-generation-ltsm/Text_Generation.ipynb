{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f1e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 22:05:56.305650: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-19 22:05:56.309407: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-19 22:05:56.319731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747692356.339646   45699 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747692356.344094   45699 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747692356.361436   45699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747692356.361450   45699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747692356.361452   45699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747692356.361454   45699 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-19 22:05:56.365751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  # type: ignore\n",
    "from keras.layers import Dense, Dropout, LSTM  # type: ignore\n",
    "from keras.optimizers import RMSprop  # type: ignore\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d252159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of trading with mexico\n",
      "    \n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. you may copy it, give it away or re-use it under the terms\n",
      "of the project gutenberg license included with this ebook or online\n",
      "at www.gutenberg.org. if you are not located in the united states,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this ebook.\n",
      "\n",
      "title: trading with mexico\n",
      "\n",
      "author: wallace thompson\n",
      "\n",
      "release date: february 26, 2025 [ebook #75469]\n",
      "\n",
      "language: english\n",
      "\n",
      "original publication: new york: dodd, mead and company, 1921\n",
      "\n",
      "credits: the online distributed proofreading team at https://www.pgdp.net (this file was produced from images generously made available by the internet archive)\n",
      "\n",
      "\n",
      "*** start of the project gutenberg ebook trading with mexico ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                              trading with\n",
      "                                 mexico\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"Trading with Mexico.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "print(raw_text[0:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae08ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = ''.join(c for c in raw_text if not c.isdigit())\n",
    "chars = sorted(list(set(raw_text)))  # List of every character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d121ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ea8c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters in the text; corpus length:  387019\n",
      "Total Vocab:  63\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters in the text; corpus length: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041266b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 38696\n"
     ]
    }
   ],
   "source": [
    "seq_length = 60  # Length of each input sequence\n",
    "step = 10        # Instead of moving 1 letter at a time, try skipping a few.\n",
    "sentences = []   # X values (Sentences)\n",
    "next_chars = []  # Y values. The character that follows the sentence defined as X\n",
    "\n",
    "for i in range(0, n_chars - seq_length, step):  # step=1 means each sentence is offset just by a single letter\n",
    "    sentences.append(raw_text[i: i + seq_length])  # Sequence in\n",
    "    next_chars.append(raw_text[i + seq_length])    # Sequence out\n",
    "\n",
    "n_patterns = len(sentences)\n",
    "print('Number of sequences:', n_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c2cf1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38696, 60, 63)\n",
      "(38696, 63)\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False  True False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "   True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False  True False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "   True False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False  True False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]\n",
      " [False  True False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False]]\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(sentences), seq_length, n_vocab), dtype=np.bool_)\n",
    "y = np.zeros((len(sentences), n_vocab), dtype=np.bool_)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[next_chars[i]]] = 1\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20062805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 22:18:04.940623: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,127</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m)             │         \u001b[38;5;34m8,127\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,431</span> (415.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,431\u001b[0m (415.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,431</span> (415.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m106,431\u001b[0m (415.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seq_length, n_vocab)))\n",
    "model.add(Dense(n_vocab, activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26deefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = \"saved_weights-{epoch:02d}-{loss:.4f}.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f09ad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 22:22:23.429672: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146270880 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.7832\n",
      "Epoch 1: loss improved from inf to 2.46960, saving model to saved_weights-01-2.4696.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 98ms/step - loss: 2.7812\n",
      "Epoch 2/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.0584\n",
      "Epoch 2: loss improved from 2.46960 to 2.01550, saving model to saved_weights-02-2.0155.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 2.0581\n",
      "Epoch 3/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.8539\n",
      "Epoch 3: loss improved from 2.01550 to 1.82964, saving model to saved_weights-03-1.8296.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - loss: 1.8537\n",
      "Epoch 4/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.6952\n",
      "Epoch 4: loss improved from 1.82964 to 1.69485, saving model to saved_weights-04-1.6949.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.6952\n",
      "Epoch 5/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.5850\n",
      "Epoch 5: loss improved from 1.69485 to 1.58921, saving model to saved_weights-05-1.5892.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - loss: 1.5851\n",
      "Epoch 6/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.4840\n",
      "Epoch 6: loss improved from 1.58921 to 1.49743, saving model to saved_weights-06-1.4974.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.4840\n",
      "Epoch 7/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.4022\n",
      "Epoch 7: loss improved from 1.49743 to 1.42244, saving model to saved_weights-07-1.4224.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.4023\n",
      "Epoch 8/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.3270\n",
      "Epoch 8: loss improved from 1.42244 to 1.35542, saving model to saved_weights-08-1.3554.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.3272\n",
      "Epoch 9/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.2663\n",
      "Epoch 9: loss improved from 1.35542 to 1.29759, saving model to saved_weights-09-1.2976.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 96ms/step - loss: 1.2665\n",
      "Epoch 10/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.2172\n",
      "Epoch 10: loss improved from 1.29759 to 1.24881, saving model to saved_weights-10-1.2488.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.2174\n",
      "Epoch 11/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.1594\n",
      "Epoch 11: loss improved from 1.24881 to 1.20024, saving model to saved_weights-11-1.2002.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.1596\n",
      "Epoch 12/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.1293\n",
      "Epoch 12: loss improved from 1.20024 to 1.17021, saving model to saved_weights-12-1.1702.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.1295\n",
      "Epoch 13/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.0874\n",
      "Epoch 13: loss improved from 1.17021 to 1.13965, saving model to saved_weights-13-1.1396.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 96ms/step - loss: 1.0875\n",
      "Epoch 14/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.0649\n",
      "Epoch 14: loss improved from 1.13965 to 1.10987, saving model to saved_weights-14-1.1099.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.0652\n",
      "Epoch 15/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.0431\n",
      "Epoch 15: loss improved from 1.10987 to 1.09205, saving model to saved_weights-15-1.0920.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.0434\n",
      "Epoch 16/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.0256\n",
      "Epoch 16: loss improved from 1.09205 to 1.07265, saving model to saved_weights-16-1.0727.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 1.0260\n",
      "Epoch 17/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.0075\n",
      "Epoch 17: loss improved from 1.07265 to 1.05036, saving model to saved_weights-17-1.0504.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - loss: 1.0078\n",
      "Epoch 18/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9948\n",
      "Epoch 18: loss improved from 1.05036 to 1.03651, saving model to saved_weights-18-1.0365.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - loss: 0.9951\n",
      "Epoch 19/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9774\n",
      "Epoch 19: loss improved from 1.03651 to 1.02216, saving model to saved_weights-19-1.0222.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.9777\n",
      "Epoch 20/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9580\n",
      "Epoch 20: loss improved from 1.02216 to 1.01319, saving model to saved_weights-20-1.0132.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - loss: 0.9583\n",
      "Epoch 21/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9649\n",
      "Epoch 21: loss improved from 1.01319 to 1.00375, saving model to saved_weights-21-1.0038.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.9650\n",
      "Epoch 22/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9431\n",
      "Epoch 22: loss improved from 1.00375 to 0.98645, saving model to saved_weights-22-0.9864.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.9434\n",
      "Epoch 23/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9259\n",
      "Epoch 23: loss improved from 0.98645 to 0.97800, saving model to saved_weights-23-0.9780.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.9262\n",
      "Epoch 24/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9130\n",
      "Epoch 24: loss improved from 0.97800 to 0.97299, saving model to saved_weights-24-0.9730.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.9134\n",
      "Epoch 25/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9138\n",
      "Epoch 25: loss improved from 0.97299 to 0.95817, saving model to saved_weights-25-0.9582.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.9141\n",
      "Epoch 26/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9049\n",
      "Epoch 26: loss improved from 0.95817 to 0.94910, saving model to saved_weights-26-0.9491.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.9052\n",
      "Epoch 27/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8788\n",
      "Epoch 27: loss improved from 0.94910 to 0.94197, saving model to saved_weights-27-0.9420.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.8792\n",
      "Epoch 28/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8903\n",
      "Epoch 28: loss improved from 0.94197 to 0.93010, saving model to saved_weights-28-0.9301.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.8904\n",
      "Epoch 29/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.8775\n",
      "Epoch 29: loss improved from 0.93010 to 0.92641, saving model to saved_weights-29-0.9264.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.8777\n",
      "Epoch 30/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.8677\n",
      "Epoch 30: loss improved from 0.92641 to 0.91557, saving model to saved_weights-30-0.9156.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.8681\n",
      "Epoch 31/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.8458\n",
      "Epoch 31: loss improved from 0.91557 to 0.89764, saving model to saved_weights-31-0.8976.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - loss: 0.8460\n",
      "Epoch 32/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8528\n",
      "Epoch 32: loss improved from 0.89764 to 0.89310, saving model to saved_weights-32-0.8931.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.8531\n",
      "Epoch 33/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8334\n",
      "Epoch 33: loss improved from 0.89310 to 0.88216, saving model to saved_weights-33-0.8822.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.8338\n",
      "Epoch 34/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8187\n",
      "Epoch 34: loss improved from 0.88216 to 0.87094, saving model to saved_weights-34-0.8709.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.8190\n",
      "Epoch 35/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8204\n",
      "Epoch 35: loss improved from 0.87094 to 0.86983, saving model to saved_weights-35-0.8698.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.8207\n",
      "Epoch 36/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.8212\n",
      "Epoch 36: loss improved from 0.86983 to 0.86154, saving model to saved_weights-36-0.8615.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.8214\n",
      "Epoch 37/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.8054\n",
      "Epoch 37: loss improved from 0.86154 to 0.85079, saving model to saved_weights-37-0.8508.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - loss: 0.8057\n",
      "Epoch 38/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7866\n",
      "Epoch 38: loss improved from 0.85079 to 0.84424, saving model to saved_weights-38-0.8442.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 99ms/step - loss: 0.7870\n",
      "Epoch 39/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.7993\n",
      "Epoch 39: loss improved from 0.84424 to 0.83967, saving model to saved_weights-39-0.8397.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.7995\n",
      "Epoch 40/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7869\n",
      "Epoch 40: loss improved from 0.83967 to 0.83345, saving model to saved_weights-40-0.8334.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - loss: 0.7870\n",
      "Epoch 41/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7853\n",
      "Epoch 41: loss improved from 0.83345 to 0.82887, saving model to saved_weights-41-0.8289.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - loss: 0.7856\n",
      "Epoch 42/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.7676\n",
      "Epoch 42: loss improved from 0.82887 to 0.81960, saving model to saved_weights-42-0.8196.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.7679\n",
      "Epoch 43/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7723\n",
      "Epoch 43: loss improved from 0.81960 to 0.80967, saving model to saved_weights-43-0.8097.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 100ms/step - loss: 0.7726\n",
      "Epoch 44/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7573\n",
      "Epoch 44: loss improved from 0.80967 to 0.80668, saving model to saved_weights-44-0.8067.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.7577\n",
      "Epoch 45/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7518\n",
      "Epoch 45: loss improved from 0.80668 to 0.80032, saving model to saved_weights-45-0.8003.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - loss: 0.7521\n",
      "Epoch 46/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7398\n",
      "Epoch 46: loss improved from 0.80032 to 0.79188, saving model to saved_weights-46-0.7919.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 99ms/step - loss: 0.7402\n",
      "Epoch 47/50\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7409\n",
      "Epoch 47: loss improved from 0.79188 to 0.78692, saving model to saved_weights-47-0.7869.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - loss: 0.7410\n",
      "Epoch 48/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7373\n",
      "Epoch 48: loss improved from 0.78692 to 0.78484, saving model to saved_weights-48-0.7848.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - loss: 0.7376\n",
      "Epoch 49/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7204\n",
      "Epoch 49: loss improved from 0.78484 to 0.77540, saving model to saved_weights-49-0.7754.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - loss: 0.7207\n",
      "Epoch 50/50\n",
      "\u001b[1m302/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7241\n",
      "Epoch 50: loss improved from 0.77540 to 0.77061, saving model to saved_weights-50-0.7706.keras\n",
      "\u001b[1m303/303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - loss: 0.7244\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(x, y,\n",
    "                    batch_size=128,\n",
    "                    epochs=50,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "model.save('my_saved_weights_50epochs.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb0bdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6092186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)  # exp of log(x), isn't this same as x??\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c04f69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Seed for our text prediction: \"roleum.\n",
      "the commercial struggle is to-day not the war for ma\"\n",
      "roleum.\n",
      "the commercial struggle is to-day not the war for ma"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "# load the network weights\n",
    "filename = \"saved_weights-50-0.7706.keras\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "#Pick a random sentence from the text as seed.\n",
    "start_index = random.randint(0, n_chars - seq_length - 1)\n",
    "\n",
    "#Initiate generated text and keep adding new predictions and print them out\n",
    "generated = ''\n",
    "sentence = raw_text[start_index: start_index + seq_length]\n",
    "generated += sentence\n",
    "\n",
    "print('----- Seed for our text prediction: \"' + sentence + '\"')\n",
    "sys.stdout.write(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "373762e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re importeres destruction,\n",
      "with the nome     thous of the totaces of the diaz agover muy gerates, on companies and nor unopsed for dried expenien business for only eages concest—ally “viblisg\n",
      "mexican mexico ime part worth well compationa ineters, government from the hat,” .ely grownty with the prom age\n",
      "vireuse, a dever yet the -create by the utherwere mexico’s as who as to uprus?t of the privame t\n"
     ]
    }
   ],
   "source": [
    "for i in range(400):  # Number of characters including spaces\n",
    "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample(preds)\n",
    "    next_char = int_to_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
