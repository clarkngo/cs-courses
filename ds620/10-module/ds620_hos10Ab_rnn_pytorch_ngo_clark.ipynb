{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5gqZWDtO8p6p"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ori_data = torch.randint(0, 10, (10005, 1))\n",
        "print(max(ori_data), min(ori_data), len(ori_data), ori_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVpLGL8e9FC7",
        "outputId": "3e269620-4244-4465-9928-2981620ca498"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9]) tensor([0]) 10005 torch.Size([10005, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature = torch.cat((ori_data[0: -5], ori_data[1: -4], ori_data[2: -3], ori_data[3: -2]), axis=-1)\n",
        "label = ori_data[4: -1]\n",
        "feature = torch.reshape(feature, shape=(-1, 4))\n",
        "label = torch.reshape(label, shape=(-1,))\n",
        "print(feature.shape, label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqIcIFdQ9Tf2",
        "outputId": "a0ad40a2-fbe1-4b0a-c996-969b49993d5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 4]) torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature = torch.nn.functional.one_hot(feature, 10)\n",
        "label = torch.nn.functional.one_hot(label, 10)\n",
        "\n",
        "x_train, x_test = feature[:7000], feature[7000:]\n",
        "y_train, y_test = label[:7000], label[7000:]\n",
        "print(x_train.shape, x_train.shape, x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBfx3LSm9WJU",
        "outputId": "cec4249e-a1c8-4c23-8f8b-03ee2d644d0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7000, 4, 10]) torch.Size([7000, 4, 10]) torch.Size([3000, 4, 10]) torch.Size([3000, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_iter(batch_size, features, labels):\n",
        "    num_examples = len(features)\n",
        "    indices = list(range(num_examples))\n",
        "    for i in range(0, num_examples, batch_size):\n",
        "        batch_indices = torch.tensor(indices[i: i + batch_size])\n",
        "        yield features[batch_indices], labels[batch_indices]"
      ],
      "metadata": {
        "id": "_IdWWi_L9ZXm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 200\n",
        "for x, y in data_iter(batch_size, x_train, y_train):\n",
        "    print(x.shape, '\\n', y.shape)\n",
        "    break\n",
        "\n",
        "torch.Size([200, 4, 10])\n",
        "torch.Size([200, 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6PgCtUc9a0E",
        "outputId": "57e36c71-a4d5-4500-9ac0-06f680a746b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([200, 4, 10]) \n",
            " torch.Size([200, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normal(shape):\n",
        "    return torch.randn(size=shape) * 0.01"
      ],
      "metadata": {
        "id": "uTRnqPMf9fi5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_params(vocab_size, num_hiddens):\n",
        "    num_inputs = num_outputs = vocab_size\n",
        "    # input part params\n",
        "    W_xh = normal((num_inputs, num_hiddens))\n",
        "    W_hh = normal((num_hiddens, num_hiddens))\n",
        "    b_h = torch.zeros(num_hiddens)\n",
        "    # output part params\n",
        "    W_hq = normal((num_hiddens, num_outputs))\n",
        "    b_q = torch.zeros(num_outputs)\n",
        "    # add gradient\n",
        "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
        "    for param in params:\n",
        "        param.requires_grad_(True)\n",
        "    return params"
      ],
      "metadata": {
        "id": "AGSTh2AT9gid"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 200\n",
        "for x, y in data_iter(batch_size, x_train, y_train):\n",
        "    print(x.shape, '\\n', y.shape)\n",
        "    break\n",
        "\n",
        "torch.Size([200, 4, 10])\n",
        "torch.Size([200, 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nt_KiC59huO",
        "outputId": "dded3369-57e3-4f93-b2b2-6dadaacf2063"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([200, 4, 10]) \n",
            " torch.Size([200, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normal(shape):\n",
        "    return torch.randn(size=shape) * 0.01"
      ],
      "metadata": {
        "id": "DGwZEEH79owx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_params(vocab_size, num_hiddens):\n",
        "    num_inputs = num_outputs = vocab_size\n",
        "    # input part params\n",
        "    W_xh = normal((num_inputs, num_hiddens))\n",
        "    W_hh = normal((num_hiddens, num_hiddens))\n",
        "    b_h = torch.zeros(num_hiddens)\n",
        "    # output part params\n",
        "    W_hq = normal((num_hiddens, num_outputs))\n",
        "    b_q = torch.zeros(num_outputs)\n",
        "    # add gradient\n",
        "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
        "    for param in params:\n",
        "        param.requires_grad_(True)\n",
        "    return params"
      ],
      "metadata": {
        "id": "rZT686dc9qFb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_rnn_state(batch_size, num_hiddens):\n",
        "    return (torch.zeros(((batch_size, num_hiddens)),))"
      ],
      "metadata": {
        "id": "FTr3iD6M9rL7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn(inputs, state, params):\n",
        "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
        "    H = state[0]\n",
        "    outputs = []\n",
        "    for X in inputs:\n",
        "        # **This is the critical line to add:**\n",
        "        # It forces X to be a 2D matrix of shape (BatchSize, Features),\n",
        "        # guaranteeing torch.mm has valid inputs.\n",
        "        X = X.reshape(-1, X.shape[-1])\n",
        "\n",
        "        H = torch.tanh(X @ W_xh + H @ W_hh + b_h)\n",
        "        Y = H @ W_hq + b_q\n",
        "        outputs.append(Y)\n",
        "    return outputs[-1], (H,)"
      ],
      "metadata": {
        "id": "BpwVhT6N9tcN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y, y_hat):\n",
        "    y_hat = y_hat.argmax(axis=1)\n",
        "    y = y.argmax(axis=1)\n",
        "    count = y_hat.type(y.dtype) == y\n",
        "    return float(count.type(y.dtype).sum() / count.shape[0])"
      ],
      "metadata": {
        "id": "vK0MGTfb9uiy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel:\n",
        "    def __init__(self, vocab_size, num_hiddens, get_params, init_state, forward_fn):\n",
        "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
        "        self.params = get_params(vocab_size, num_hiddens)\n",
        "        self.init_state, self.forward_fn = init_state, forward_fn\n",
        "\n",
        "    def __call__(self, X, state):\n",
        "        X = X.type(torch.float32)\n",
        "        return self.forward_fn(X, state, self.params)\n",
        "\n",
        "    def begin_state(self, batch_size):\n",
        "        return self.init_state(batch_size, self.num_hiddens)"
      ],
      "metadata": {
        "id": "7PSt1W3190Ja"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_net = RNNModel(vocab_size=10, num_hiddens=32, init_state=init_rnn_state,\n",
        "                   forward_fn=rnn, get_params=get_params)"
      ],
      "metadata": {
        "id": "AYgDNviU97N7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.MSELoss()\n",
        "updater = torch.optim.Adam(RNN_net.params, lr=0.001)"
      ],
      "metadata": {
        "id": "rXMeHqE09-VM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(net, loss, updater, batch_size, x_train, y_train):\n",
        "    L = []\n",
        "    ACC = []\n",
        "    for X, y in data_iter(batch_size, x_train, y_train):\n",
        "        state = net.begin_state(batch_size)\n",
        "        y_hat, state = net(torch.transpose(X, 0, 1), state)\n",
        "        y = y.type(y_hat.dtype)\n",
        "        l = loss(y, y_hat)\n",
        "        L.append(l)\n",
        "        ACC.append(accuracy(y, y_hat))\n",
        "        updater.zero_grad()\n",
        "        l.backward()\n",
        "        updater.step()\n",
        "    return float(sum(L) / len(L)), float(sum(ACC) / len(ACC))"
      ],
      "metadata": {
        "id": "cdhcctUE-AM-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_torch_layer = torch.nn.RNN(10, 32)\n",
        "RNN_torch_class = torch.nn.Sequential(\n",
        "    torch.nn.Linear(32, 10),\n",
        "    torch.nn.Softmax()\n",
        ")\n",
        "\n",
        "RNN_torch_params = list(RNN_torch_layer.parameters()) + list(RNN_torch_class.parameters())\n",
        "\n",
        "RNN_torch_updater = torch.optim.Adam(RNN_torch_params, lr=0.001)"
      ],
      "metadata": {
        "id": "wx9E_SLf-Ch8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100\n",
        "for _ in range(epoch):\n",
        "    L = []\n",
        "    ACC = []\n",
        "    for x, y in data_iter(batch_size, x_train, y_train):\n",
        "        x = x.type(torch.float32)\n",
        "        y_hat, state = RNN_torch_layer(torch.transpose(x, 0, 1))\n",
        "        y_hat = RNN_torch_class(y_hat)\n",
        "        y = y.type(y_hat.dtype)\n",
        "        l = loss(y, y_hat[-1])\n",
        "        L.append(l)\n",
        "        ACC.append(accuracy(y, y_hat[-1]))\n",
        "        RNN_torch_updater.zero_grad()\n",
        "        l.backward()\n",
        "        RNN_torch_updater.step()\n",
        "    print('epoch:', _, 'loss:', float(sum(L) / len(L)), 'accuracy:', float(sum(ACC) / len(ACC)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co0MXfAo-Qsb",
        "outputId": "bede9494-0f92-49bc-d8aa-91d4f302f845"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1775: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/tmp/ipython-input-1378161325.py:16: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  print('epoch:', _, 'loss:', float(sum(L) / len(L)), 'accuracy:', float(sum(ACC) / len(ACC)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: 0.10459031164646149 accuracy: 0.101857143001897\n",
            "epoch: 1 loss: 0.09071774035692215 accuracy: 0.10357142825211797\n",
            "epoch: 2 loss: 0.09003285318613052 accuracy: 0.10428571413670268\n",
            "epoch: 3 loss: 0.09002270549535751 accuracy: 0.09985714256763459\n",
            "epoch: 4 loss: 0.0900166779756546 accuracy: 0.10185714342764446\n",
            "epoch: 5 loss: 0.09001239389181137 accuracy: 0.10442857167550496\n",
            "epoch: 6 loss: 0.09000804275274277 accuracy: 0.10442857167550496\n",
            "epoch: 7 loss: 0.09000374376773834 accuracy: 0.10499999980841364\n",
            "epoch: 8 loss: 0.0899994820356369 accuracy: 0.10514285638928414\n",
            "epoch: 9 loss: 0.08999525755643845 accuracy: 0.10457142793706485\n",
            "epoch: 10 loss: 0.08999105542898178 accuracy: 0.10614285724503654\n",
            "epoch: 11 loss: 0.08998681604862213 accuracy: 0.10657142837132727\n",
            "epoch: 12 loss: 0.08998256921768188 accuracy: 0.10671428591012955\n",
            "epoch: 13 loss: 0.08997827768325806 accuracy: 0.10799999982118606\n",
            "epoch: 14 loss: 0.08997391164302826 accuracy: 0.10971428560359138\n",
            "epoch: 15 loss: 0.08996948599815369 accuracy: 0.1109999995146479\n",
            "epoch: 16 loss: 0.08996497094631195 accuracy: 0.11185714304447174\n",
            "epoch: 17 loss: 0.08996034413576126 accuracy: 0.111857142831598\n",
            "epoch: 18 loss: 0.08995559066534042 accuracy: 0.11285714251654488\n",
            "epoch: 19 loss: 0.08995072543621063 accuracy: 0.11300000069396836\n",
            "epoch: 20 loss: 0.0899457260966301 accuracy: 0.11328571342996188\n",
            "epoch: 21 loss: 0.08994057774543762 accuracy: 0.11571428637419429\n",
            "epoch: 22 loss: 0.08993528038263321 accuracy: 0.11614285686186382\n",
            "epoch: 23 loss: 0.08992983400821686 accuracy: 0.118857142329216\n",
            "epoch: 24 loss: 0.08992426842451096 accuracy: 0.11942857120718275\n",
            "epoch: 25 loss: 0.0899185761809349 accuracy: 0.11928571334906987\n",
            "epoch: 26 loss: 0.0899127796292305 accuracy: 0.11971428543329239\n",
            "epoch: 27 loss: 0.08990689367055893 accuracy: 0.12128571463482721\n",
            "epoch: 28 loss: 0.08990097790956497 accuracy: 0.12071428575686045\n",
            "epoch: 29 loss: 0.08989503234624863 accuracy: 0.1211428580539567\n",
            "epoch: 30 loss: 0.08988906443119049 accuracy: 0.12328571379184723\n",
            "epoch: 31 loss: 0.08988314121961594 accuracy: 0.12300000041723251\n",
            "epoch: 32 loss: 0.08987719565629959 accuracy: 0.12257142854588372\n",
            "epoch: 33 loss: 0.08987128734588623 accuracy: 0.1251428553036281\n",
            "epoch: 34 loss: 0.08986537903547287 accuracy: 0.1252857140132359\n",
            "epoch: 35 loss: 0.0898594781756401 accuracy: 0.1271428576537541\n",
            "epoch: 36 loss: 0.08985358476638794 accuracy: 0.12842857092618942\n",
            "epoch: 37 loss: 0.08984767645597458 accuracy: 0.1279999988419669\n",
            "epoch: 38 loss: 0.08984176814556122 accuracy: 0.12928571424313953\n",
            "epoch: 39 loss: 0.08983585983514786 accuracy: 0.12957142804350172\n",
            "epoch: 40 loss: 0.08982996642589569 accuracy: 0.12985714312110627\n",
            "epoch: 41 loss: 0.08982408791780472 accuracy: 0.13042857157332557\n",
            "epoch: 42 loss: 0.08981825411319733 accuracy: 0.13128571403878075\n",
            "epoch: 43 loss: 0.0898125022649765 accuracy: 0.13128571382590704\n",
            "epoch: 44 loss: 0.08980681002140045 accuracy: 0.13085714195455825\n",
            "epoch: 45 loss: 0.08980123698711395 accuracy: 0.13085714195455825\n",
            "epoch: 46 loss: 0.08979576081037521 accuracy: 0.13171428548438208\n",
            "epoch: 47 loss: 0.08979038894176483 accuracy: 0.1318571429167475\n",
            "epoch: 48 loss: 0.08978511393070221 accuracy: 0.13157142783914294\n",
            "epoch: 49 loss: 0.08977997303009033 accuracy: 0.13171428569725582\n",
            "epoch: 50 loss: 0.08977490663528442 accuracy: 0.13257142880133221\n",
            "epoch: 51 loss: 0.08976994454860687 accuracy: 0.13199999928474426\n",
            "epoch: 52 loss: 0.08976507186889648 accuracy: 0.13171428569725582\n",
            "epoch: 53 loss: 0.08976026624441147 accuracy: 0.13199999992336545\n",
            "epoch: 54 loss: 0.08975554257631302 accuracy: 0.1327142838920866\n",
            "epoch: 55 loss: 0.08975087851285934 accuracy: 0.13285714324031558\n",
            "epoch: 56 loss: 0.08974626660346985 accuracy: 0.1332857140472957\n",
            "epoch: 57 loss: 0.08974172174930573 accuracy: 0.13442857159035546\n",
            "epoch: 58 loss: 0.08973722904920578 accuracy: 0.1352857151201793\n",
            "epoch: 59 loss: 0.08973278850317001 accuracy: 0.13614285801138196\n",
            "epoch: 60 loss: 0.08972838521003723 accuracy: 0.13700000090258463\n",
            "epoch: 61 loss: 0.08972405642271042 accuracy: 0.13814285801989692\n",
            "epoch: 62 loss: 0.08971978724002838 accuracy: 0.1381428573812757\n",
            "epoch: 63 loss: 0.08971553295850754 accuracy: 0.13842857224600655\n",
            "epoch: 64 loss: 0.08971133828163147 accuracy: 0.13842857224600655\n",
            "epoch: 65 loss: 0.08970718830823898 accuracy: 0.13828571481364113\n",
            "epoch: 66 loss: 0.08970311284065247 accuracy: 0.13871428604636873\n",
            "epoch: 67 loss: 0.08969905227422714 accuracy: 0.13900000069822585\n",
            "epoch: 68 loss: 0.0896950513124466 accuracy: 0.14014285824128558\n",
            "epoch: 69 loss: 0.08969105035066605 accuracy: 0.14000000017029898\n",
            "epoch: 70 loss: 0.08968711644411087 accuracy: 0.13971428615706308\n",
            "epoch: 71 loss: 0.08968319743871689 accuracy: 0.14057142862251826\n",
            "epoch: 72 loss: 0.0896793007850647 accuracy: 0.14114285771335874\n",
            "epoch: 73 loss: 0.08967544883489609 accuracy: 0.14128571493285044\n",
            "epoch: 74 loss: 0.08967159688472748 accuracy: 0.1418571440236909\n",
            "epoch: 75 loss: 0.08966776728630066 accuracy: 0.14242857141154153\n",
            "epoch: 76 loss: 0.08966395258903503 accuracy: 0.14300000028950827\n",
            "epoch: 77 loss: 0.08966013044118881 accuracy: 0.14314285793474743\n",
            "epoch: 78 loss: 0.08965634554624557 accuracy: 0.14357143001896994\n",
            "epoch: 79 loss: 0.08965255320072174 accuracy: 0.1444285722715514\n",
            "epoch: 80 loss: 0.0896487608551979 accuracy: 0.1442857154778072\n",
            "epoch: 81 loss: 0.08964496105909348 accuracy: 0.14457143012966428\n",
            "epoch: 82 loss: 0.08964116126298904 accuracy: 0.14528571516275407\n",
            "epoch: 83 loss: 0.08963734656572342 accuracy: 0.14614285741533553\n",
            "epoch: 84 loss: 0.0896335244178772 accuracy: 0.14614285762820925\n",
            "epoch: 85 loss: 0.08962967246770859 accuracy: 0.14514285815613612\n",
            "epoch: 86 loss: 0.08962580561637878 accuracy: 0.14399999997445515\n",
            "epoch: 87 loss: 0.08962193131446838 accuracy: 0.1450000000851495\n",
            "epoch: 88 loss: 0.0896180272102356 accuracy: 0.14599999977009637\n",
            "epoch: 89 loss: 0.08961409330368042 accuracy: 0.14657142886093685\n",
            "epoch: 90 loss: 0.08961011469364166 accuracy: 0.1454285715307508\n",
            "epoch: 91 loss: 0.08960609883069992 accuracy: 0.1462857146348272\n",
            "epoch: 92 loss: 0.0896020457148552 accuracy: 0.14685714351279394\n",
            "epoch: 93 loss: 0.08959796279668808 accuracy: 0.14685714329992022\n",
            "epoch: 94 loss: 0.0895938128232956 accuracy: 0.1470000011580331\n",
            "epoch: 95 loss: 0.08958961069583893 accuracy: 0.14728571623563766\n",
            "epoch: 96 loss: 0.08958534896373749 accuracy: 0.1472857158098902\n",
            "epoch: 97 loss: 0.08958102762699127 accuracy: 0.14628571506057467\n",
            "epoch: 98 loss: 0.08957664668560028 accuracy: 0.14657142949955804\n",
            "epoch: 99 loss: 0.08957220613956451 accuracy: 0.1471428571002824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = []\n",
        "test_accuracy = []\n",
        "for x, y in data_iter(batch_size, x_test, y_test):\n",
        "    state = RNN_net.begin_state(batch_size)\n",
        "    y_hat, state = RNN_net(torch.transpose(x, 0, 1), state)\n",
        "    y = y.type(y_hat.dtype)\n",
        "    l = loss(y, y_hat)\n",
        "    test_loss.append(l)\n",
        "    test_accuracy.append(accuracy(y, y_hat))\n",
        "    updater.zero_grad()\n",
        "    l.backward()\n",
        "    updater.step()\n",
        "print('test loss:', float(sum(test_loss) / len(test_loss)), 'accuracy:', float(sum(test_accuracy) / len(test_accuracy)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx87Vtle-Tig",
        "outputId": "d67fa43e-bb97-4370-cc80-acdcf7457da0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.09791617840528488 accuracy: 0.09899999871850014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_torch_layer = torch.nn.LSTM(10, 32)\n",
        "LSTM_torch_class = torch.nn.Sequential(\n",
        "    torch.nn.Linear(32, 10),\n",
        "    torch.nn.Softmax()\n",
        ")\n",
        "\n",
        "LSTM_torch_params = list(LSTM_torch_layer.parameters()) + list(LSTM_torch_class.parameters())\n",
        "\n",
        "LSTM_torch_updater = torch.optim.Adam(LSTM_torch_params, lr=0.001)"
      ],
      "metadata": {
        "id": "CqaL361y-Y5i"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100\n",
        "for _ in range(epoch):\n",
        "    L = []\n",
        "    ACC = []\n",
        "    for x, y in data_iter(batch_size, x_train, y_train):\n",
        "        x = x.type(torch.float32)\n",
        "        y_hat, state = LSTM_torch_layer(torch.transpose(x, 0, 1))\n",
        "        y_hat = LSTM_torch_class(y_hat)\n",
        "        y = y.type(y_hat.dtype)\n",
        "        l = loss(y, y_hat[-1])\n",
        "        L.append(l)\n",
        "        ACC.append(accuracy(y, y_hat[-1]))\n",
        "        LSTM_torch_updater.zero_grad()\n",
        "        l.backward()\n",
        "        LSTM_torch_updater.step()\n",
        "    print('epoch:', _, 'loss:', float(sum(L) / len(L)), 'accuracy:', float(sum(ACC) / len(ACC)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jab83srM-bK_",
        "outputId": "53c5eee8-6738-47de-910c-9611d65119ad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: 0.11041231453418732 accuracy: 0.09971428683825902\n",
            "epoch: 1 loss: 0.09715361893177032 accuracy: 0.10499999948910305\n",
            "epoch: 2 loss: 0.09011740237474442 accuracy: 0.09614285741533551\n",
            "epoch: 3 loss: 0.09000716358423233 accuracy: 0.09771428661687033\n",
            "epoch: 4 loss: 0.09000106900930405 accuracy: 0.09757142939737865\n",
            "epoch: 5 loss: 0.08999975770711899 accuracy: 0.09942857154778072\n",
            "epoch: 6 loss: 0.08999839425086975 accuracy: 0.10071428577814784\n",
            "epoch: 7 loss: 0.08999689668416977 accuracy: 0.10242857124124255\n",
            "epoch: 8 loss: 0.08999526500701904 accuracy: 0.10214285637651171\n",
            "epoch: 9 loss: 0.08999354392290115 accuracy: 0.10271428674459457\n",
            "epoch: 10 loss: 0.0899917259812355 accuracy: 0.10371428621666771\n",
            "epoch: 11 loss: 0.08998984098434448 accuracy: 0.10414285681077412\n",
            "epoch: 12 loss: 0.0899878740310669 accuracy: 0.10457142868212291\n",
            "epoch: 13 loss: 0.08998587727546692 accuracy: 0.10385714343615941\n",
            "epoch: 14 loss: 0.08998379111289978 accuracy: 0.10571428537368774\n",
            "epoch: 15 loss: 0.08998165279626846 accuracy: 0.10542857157332557\n",
            "epoch: 16 loss: 0.08997946977615356 accuracy: 0.10414285723652159\n",
            "epoch: 17 loss: 0.08997722715139389 accuracy: 0.10499999927622931\n",
            "epoch: 18 loss: 0.08997494727373123 accuracy: 0.10557142826063293\n",
            "epoch: 19 loss: 0.0899725928902626 accuracy: 0.10685714259743691\n",
            "epoch: 20 loss: 0.0899701938033104 accuracy: 0.10714285714285714\n",
            "epoch: 21 loss: 0.08996773511171341 accuracy: 0.10857142816696848\n",
            "epoch: 22 loss: 0.08996523171663284 accuracy: 0.1084285712667874\n",
            "epoch: 23 loss: 0.0899626761674881 accuracy: 0.1091428568320615\n",
            "epoch: 24 loss: 0.08996005356311798 accuracy: 0.11057142849479402\n",
            "epoch: 25 loss: 0.08995738625526428 accuracy: 0.11157142775399344\n",
            "epoch: 26 loss: 0.08995465934276581 accuracy: 0.11228571470294679\n",
            "epoch: 27 loss: 0.08995185792446136 accuracy: 0.11242857224174908\n",
            "epoch: 28 loss: 0.08994902670383453 accuracy: 0.11428571332778249\n",
            "epoch: 29 loss: 0.08994615823030472 accuracy: 0.11385714284011296\n",
            "epoch: 30 loss: 0.08994318544864655 accuracy: 0.11514285696404321\n",
            "epoch: 31 loss: 0.08994019031524658 accuracy: 0.11557142840964453\n",
            "epoch: 32 loss: 0.08993712812662125 accuracy: 0.11614285686186382\n",
            "epoch: 33 loss: 0.08993402868509293 accuracy: 0.11657142915896007\n",
            "epoch: 34 loss: 0.08993086963891983 accuracy: 0.11728571483067103\n",
            "epoch: 35 loss: 0.08992765843868256 accuracy: 0.11871428617409298\n",
            "epoch: 36 loss: 0.0899244099855423 accuracy: 0.11700000017881393\n",
            "epoch: 37 loss: 0.08992111682891846 accuracy: 0.11685714317219598\n",
            "epoch: 38 loss: 0.08991775661706924 accuracy: 0.1162857147199767\n",
            "epoch: 39 loss: 0.08991435915231705 accuracy: 0.11757142884390695\n",
            "epoch: 40 loss: 0.08991093188524246 accuracy: 0.11828571408987046\n",
            "epoch: 41 loss: 0.0899074524641037 accuracy: 0.11842857109648841\n",
            "epoch: 42 loss: 0.08990392833948135 accuracy: 0.11899999954870769\n",
            "epoch: 43 loss: 0.08990036696195602 accuracy: 0.11857142746448517\n",
            "epoch: 44 loss: 0.08989675343036652 accuracy: 0.1185714270387377\n",
            "epoch: 45 loss: 0.08989311009645462 accuracy: 0.11771428553121431\n",
            "epoch: 46 loss: 0.08988943696022034 accuracy: 0.11757142852459634\n",
            "epoch: 47 loss: 0.08988570421934128 accuracy: 0.1191428576196943\n",
            "epoch: 48 loss: 0.08988195657730103 accuracy: 0.11999999965940203\n",
            "epoch: 49 loss: 0.08987817913293839 accuracy: 0.1199999991272177\n",
            "epoch: 50 loss: 0.08987434953451157 accuracy: 0.11942857035568782\n",
            "epoch: 51 loss: 0.08987049758434296 accuracy: 0.118857142329216\n",
            "epoch: 52 loss: 0.08986661583185196 accuracy: 0.1192857135619436\n",
            "epoch: 53 loss: 0.08986271172761917 accuracy: 0.11985714201416288\n",
            "epoch: 54 loss: 0.0898587629199028 accuracy: 0.1200000000851495\n",
            "epoch: 55 loss: 0.08985478430986404 accuracy: 0.12000000061733382\n",
            "epoch: 56 loss: 0.08985079079866409 accuracy: 0.12057142832449504\n",
            "epoch: 57 loss: 0.08984677493572235 accuracy: 0.12128571420907974\n",
            "epoch: 58 loss: 0.08984275162220001 accuracy: 0.1209999999829701\n",
            "epoch: 59 loss: 0.08983869850635529 accuracy: 0.12214285688740867\n",
            "epoch: 60 loss: 0.08983462303876877 accuracy: 0.12214285752602987\n",
            "epoch: 61 loss: 0.08983053267002106 accuracy: 0.1220000011580331\n",
            "epoch: 62 loss: 0.08982643485069275 accuracy: 0.12171428629330226\n",
            "epoch: 63 loss: 0.08982232958078384 accuracy: 0.12242857185857636\n",
            "epoch: 64 loss: 0.08981819450855255 accuracy: 0.12257142790726253\n",
            "epoch: 65 loss: 0.08981406688690186 accuracy: 0.12285714213337218\n",
            "epoch: 66 loss: 0.08980992436408997 accuracy: 0.12399999988930566\n",
            "epoch: 67 loss: 0.08980577439069748 accuracy: 0.12500000042574747\n",
            "epoch: 68 loss: 0.08980163186788559 accuracy: 0.12542857155203818\n",
            "epoch: 69 loss: 0.0897974893450737 accuracy: 0.12600000043000495\n",
            "epoch: 70 loss: 0.08979335427284241 accuracy: 0.12628571412393025\n",
            "epoch: 71 loss: 0.08978919684886932 accuracy: 0.1261428564786911\n",
            "epoch: 72 loss: 0.08978506177663803 accuracy: 0.12628571348530906\n",
            "epoch: 73 loss: 0.08978091925382614 accuracy: 0.125857141826834\n",
            "epoch: 74 loss: 0.08977675437927246 accuracy: 0.12614285669156483\n",
            "epoch: 75 loss: 0.08977261930704117 accuracy: 0.12642857155629567\n",
            "epoch: 76 loss: 0.08976845443248749 accuracy: 0.12685714406626566\n",
            "epoch: 77 loss: 0.089764304459095 accuracy: 0.12742857209273747\n",
            "epoch: 78 loss: 0.08976010233163834 accuracy: 0.12771428610597338\n",
            "epoch: 79 loss: 0.08975593000650406 accuracy: 0.12771428610597338\n",
            "epoch: 80 loss: 0.0897517129778862 accuracy: 0.12828571498394012\n",
            "epoch: 81 loss: 0.08974746614694595 accuracy: 0.1299999999148505\n",
            "epoch: 82 loss: 0.08974320441484451 accuracy: 0.13085714238030569\n",
            "epoch: 83 loss: 0.08973890542984009 accuracy: 0.1308571430189269\n",
            "epoch: 84 loss: 0.08973457664251328 accuracy: 0.13057142879281725\n",
            "epoch: 85 loss: 0.08973022550344467 accuracy: 0.1307142864380564\n",
            "epoch: 86 loss: 0.08972581475973129 accuracy: 0.13200000056198666\n",
            "epoch: 87 loss: 0.08972132951021194 accuracy: 0.13342857233115604\n",
            "epoch: 88 loss: 0.089716836810112 accuracy: 0.1347142858164651\n",
            "epoch: 89 loss: 0.08971230685710907 accuracy: 0.133571429337774\n",
            "epoch: 90 loss: 0.08970769494771957 accuracy: 0.13457142880984715\n",
            "epoch: 91 loss: 0.0897030457854271 accuracy: 0.13500000004257476\n",
            "epoch: 92 loss: 0.08969832956790924 accuracy: 0.1342857145837375\n",
            "epoch: 93 loss: 0.08969355374574661 accuracy: 0.13528571469443185\n",
            "epoch: 94 loss: 0.0896887332201004 accuracy: 0.13385714335100993\n",
            "epoch: 95 loss: 0.08968380838632584 accuracy: 0.1355714282819203\n",
            "epoch: 96 loss: 0.0896788015961647 accuracy: 0.13685714240585053\n",
            "epoch: 97 loss: 0.0896737352013588 accuracy: 0.13742857170956477\n",
            "epoch: 98 loss: 0.08966857194900513 accuracy: 0.13828571438789367\n",
            "epoch: 99 loss: 0.08966332674026489 accuracy: 0.13814285674265453\n"
          ]
        }
      ]
    }
  ]
}