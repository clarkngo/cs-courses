{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aaZyNybb1L7n"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ori_data = []\n",
        "for i in range(10005):\n",
        "    ori_data.append(random.randint(0, 9))\n",
        "print(max(ori_data), min(ori_data), len(ori_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iJ6FcAsR1cb_",
        "outputId": "fc8a48e6-12ee-4be2-cd0e-b778be153993"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 0 10005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ori_data = tf.reshape(tf.convert_to_tensor(ori_data), shape=[-1, 1])\n",
        "print(ori_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mvUnE_sG1es0",
        "outputId": "0291d25b-67eb-4254-ab29-f6ec441e1c92"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10005, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature = tf.concat([ori_data[0:-5], ori_data[1:-4], ori_data[2:-3], ori_data[3:-2]], axis=-1)\n",
        "feature = tf.reshape(feature, shape=[-1, 4])\n",
        "label = ori_data[4:]\n",
        "label = tf.reshape(label, shape=[-1,])\n",
        "print(feature.shape, label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nAiSdCg21-0w",
        "outputId": "f6a51392-4098-445d-9cef-2afb8fdb4df7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 4) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature = tf.one_hot(feature, 10, dtype=tf.float32)\n",
        "label = tf.one_hot(label, 10, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "S_x3BD6Q1_ao"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = feature[:7000], feature[7000:]\n",
        "y_train, y_test = label[:7000], label[7000:]\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-hSqKcJ62EBC",
        "outputId": "01097620-8f09-4508-e374-e127e5fd1d29"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7000, 4, 10) (7000, 10) (3000, 4, 10) (3000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_iter(batch_size, features, labels):\n",
        "    num_examples = len(features)\n",
        "    indices = list(range(num_examples))\n",
        "    for i in range(0, num_examples, batch_size):\n",
        "        j = tf.constant(indices[i: min(i + batch_size, num_examples)])\n",
        "        yield tf.gather(features, j), tf.gather(labels, j)"
      ],
      "metadata": {
        "id": "ukTyzDgF2FQV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 200\n",
        "for x, y in data_iter(batch_size, x_train, y_train):\n",
        "    print(x.shape, '\\n', y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zyeYUShV2TRq",
        "outputId": "4618c6ad-50fc-43d8-cbf6-edf2492c5705"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 4, 10) \n",
            " (200, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normal(shape):\n",
        "    return tf.random.normal(shape=shape, stddev=0.01, mean=0, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "DymqKSK74txq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_params(vocab_size, num_hiddens):\n",
        "    num_inputs = num_outputs = vocab_size\n",
        "\n",
        "    # input part params\n",
        "    W_xh = tf.Variable(normal((num_inputs, num_hiddens)), dtype=tf.float32)\n",
        "    W_hh = tf.Variable(normal((num_hiddens, num_hiddens)), dtype=tf.float32)\n",
        "    b_h = tf.Variable(tf.zeros(num_hiddens), dtype=tf.float32)\n",
        "\n",
        "    # output part params\n",
        "    W_hq = tf.Variable(normal((num_hiddens, num_outputs)), dtype=tf.float32)\n",
        "    b_q = tf.Variable(tf.zeros(num_outputs), dtype=tf.float32)\n",
        "\n",
        "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
        "    return params"
      ],
      "metadata": {
        "id": "z5bZzlc72iYS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_rnn_state(batch_size, num_hiddens):\n",
        "    return (tf.zeros((batch_size, num_hiddens)), )"
      ],
      "metadata": {
        "id": "XXfhOd8N2jAu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn(inputs, state, params):\n",
        "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
        "    H = state\n",
        "    outputs = []\n",
        "    for X in inputs:\n",
        "        X = tf.reshape(X, (-1, W_xh.shape[0]))\n",
        "        H = tf.tanh(tf.matmul(X, W_xh) + tf.matmul(H, W_hh) + b_h)\n",
        "        Y = tf.matmul(H, W_hq) + b_q\n",
        "        outputs.append(Y)\n",
        "    return outputs[-1], (H, )"
      ],
      "metadata": {
        "id": "5Hpm03fh2wl7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y, y_hat):\n",
        "    y_hat = tf.argmax(y_hat, axis=1)\n",
        "    y = tf.argmax(y, axis=1)\n",
        "    count = y_hat == y\n",
        "    return float(tf.reduce_sum(tf.cast(count, dtype=y.dtype)) / y.shape[0])"
      ],
      "metadata": {
        "id": "t0wPa-l62xGO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel:\n",
        "    def __init__(self, vocab_size, num_hiddens, init_state, forward_fn, get_params):\n",
        "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
        "        self.init_state, self.forward_fn = init_state, forward_fn\n",
        "        self.trainable_variables = get_params(vocab_size, num_hiddens)\n",
        "\n",
        "    def __call__(self, X, state):\n",
        "        X = tf.cast(X, tf.float32)\n",
        "        return self.forward_fn(X, state, self.trainable_variables)\n",
        "\n",
        "    def begin_state(self, batch_size):\n",
        "        return self.init_state(batch_size, self.num_hiddens)"
      ],
      "metadata": {
        "id": "KjzBXFjL24qU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_net = RNNModel(vocab_size=10, num_hiddens=32, init_state=init_rnn_state,\n",
        "                   forward_fn=rnn, get_params=get_params)"
      ],
      "metadata": {
        "id": "osF2JYOR4pQy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "updater = tf.keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "kKKTboSV4YiA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(net, loss, updater, batch_size, x_train, y_train):\n",
        "    L = []\n",
        "    ACC = []\n",
        "    for x, y in data_iter(batch_size, x_train, y_train):\n",
        "        state = net.begin_state(batch_size)\n",
        "        with tf.GradientTape(True) as g:\n",
        "            y_hat, state = net(tf.transpose(x, [1, 0, 2]), state)\n",
        "            y_hat_fixed = tf.squeeze(y_hat, axis=0)\n",
        "            l = loss(y, y_hat_fixed)\n",
        "        L.append(l)\n",
        "        ACC.append(accuracy(y, y_hat_fixed))\n",
        "        params = net.trainable_variables\n",
        "        grads = g.gradient(l, params)\n",
        "        updater.apply_gradients(zip(grads, params))\n",
        "    return float(sum(L) / len(L)), float(sum(ACC) / len(ACC))"
      ],
      "metadata": {
        "id": "h6ci6Ez64Zt_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100\n",
        "for _ in range(epoch):\n",
        "    l, acc = train_epoch(RNN_net, loss, updater, batch_size, x_train, y_train)\n",
        "    print('epoch', _ + 1, 'loss', l, 'accuracy', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nOxtf5V24alN",
        "outputId": "f59955b6-d4e4-4800-8beb-4fc5e4fe621b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 loss 0.5003222227096558 accuracy 0.10085714285714287\n",
            "epoch 2 loss 0.35151228308677673 accuracy 0.09857142857142857\n",
            "epoch 3 loss 0.3274555802345276 accuracy 0.09785714285714285\n",
            "epoch 4 loss 0.325801819562912 accuracy 0.10128571428571428\n",
            "epoch 5 loss 0.3254574239253998 accuracy 0.09785714285714285\n",
            "epoch 6 loss 0.325308620929718 accuracy 0.09428571428571429\n",
            "epoch 7 loss 0.3252190053462982 accuracy 0.09342857142857143\n",
            "epoch 8 loss 0.3251616358757019 accuracy 0.09414285714285714\n",
            "epoch 9 loss 0.32512366771698 accuracy 0.093\n",
            "epoch 10 loss 0.32509809732437134 accuracy 0.09314285714285715\n",
            "epoch 11 loss 0.3250799775123596 accuracy 0.094\n",
            "epoch 12 loss 0.3250660300254822 accuracy 0.09471428571428571\n",
            "epoch 13 loss 0.3250541090965271 accuracy 0.09542857142857142\n",
            "epoch 14 loss 0.32504287362098694 accuracy 0.09557142857142857\n",
            "epoch 15 loss 0.32503148913383484 accuracy 0.09685714285714286\n",
            "epoch 16 loss 0.3250196576118469 accuracy 0.09657142857142857\n",
            "epoch 17 loss 0.3250068426132202 accuracy 0.09842857142857142\n",
            "epoch 18 loss 0.32499295473098755 accuracy 0.09985714285714287\n",
            "epoch 19 loss 0.3249780535697937 accuracy 0.10071428571428571\n",
            "epoch 20 loss 0.32496175169944763 accuracy 0.10071428571428571\n",
            "epoch 21 loss 0.32494425773620605 accuracy 0.10228571428571429\n",
            "epoch 22 loss 0.3249254524707794 accuracy 0.10342857142857143\n",
            "epoch 23 loss 0.32490527629852295 accuracy 0.10457142857142858\n",
            "epoch 24 loss 0.32488396763801575 accuracy 0.10485714285714286\n",
            "epoch 25 loss 0.3248613774776459 accuracy 0.10471428571428572\n",
            "epoch 26 loss 0.3248378038406372 accuracy 0.10485714285714286\n",
            "epoch 27 loss 0.3248133063316345 accuracy 0.10557142857142858\n",
            "epoch 28 loss 0.324787974357605 accuracy 0.10585714285714286\n",
            "epoch 29 loss 0.32476210594177246 accuracy 0.10828571428571429\n",
            "epoch 30 loss 0.3247356712818146 accuracy 0.10814285714285715\n",
            "epoch 31 loss 0.3247089684009552 accuracy 0.10871428571428572\n",
            "epoch 32 loss 0.32468196749687195 accuracy 0.11028571428571429\n",
            "epoch 33 loss 0.3246549069881439 accuracy 0.11071428571428571\n",
            "epoch 34 loss 0.32462769746780396 accuracy 0.11314285714285714\n",
            "epoch 35 loss 0.324600487947464 accuracy 0.1147142857142857\n",
            "epoch 36 loss 0.32457318902015686 accuracy 0.1147142857142857\n",
            "epoch 37 loss 0.3245459198951721 accuracy 0.1147142857142857\n",
            "epoch 38 loss 0.3245185911655426 accuracy 0.11528571428571428\n",
            "epoch 39 loss 0.3244912624359131 accuracy 0.11585714285714285\n",
            "epoch 40 loss 0.32446393370628357 accuracy 0.1147142857142857\n",
            "epoch 41 loss 0.3244365453720093 accuracy 0.11757142857142858\n",
            "epoch 42 loss 0.3244090974330902 accuracy 0.1172857142857143\n",
            "epoch 43 loss 0.32438164949417114 accuracy 0.11885714285714286\n",
            "epoch 44 loss 0.32435399293899536 accuracy 0.11871428571428572\n",
            "epoch 45 loss 0.32432621717453003 accuracy 0.11957142857142856\n",
            "epoch 46 loss 0.3242981433868408 accuracy 0.12085714285714287\n",
            "epoch 47 loss 0.3242698907852173 accuracy 0.12199999999999998\n",
            "epoch 48 loss 0.32424136996269226 accuracy 0.12228571428571429\n",
            "epoch 49 loss 0.3242127001285553 accuracy 0.12214285714285715\n",
            "epoch 50 loss 0.32418394088745117 accuracy 0.12285714285714285\n",
            "epoch 51 loss 0.32415536046028137 accuracy 0.12285714285714285\n",
            "epoch 52 loss 0.32412707805633545 accuracy 0.12342857142857144\n",
            "epoch 53 loss 0.32409918308258057 accuracy 0.12428571428571428\n",
            "epoch 54 loss 0.3240717351436615 accuracy 0.124\n",
            "epoch 55 loss 0.324044793844223 accuracy 0.12442857142857144\n",
            "epoch 56 loss 0.32401829957962036 accuracy 0.126\n",
            "epoch 57 loss 0.3239918351173401 accuracy 0.12457142857142858\n",
            "epoch 58 loss 0.32396528124809265 accuracy 0.12485714285714286\n",
            "epoch 59 loss 0.3239385187625885 accuracy 0.12585714285714286\n",
            "epoch 60 loss 0.32391107082366943 accuracy 0.12614285714285714\n",
            "epoch 61 loss 0.3238828480243683 accuracy 0.12714285714285714\n",
            "epoch 62 loss 0.32385361194610596 accuracy 0.1277142857142857\n",
            "epoch 63 loss 0.3238231837749481 accuracy 0.1287142857142857\n",
            "epoch 64 loss 0.32379135489463806 accuracy 0.1295714285714286\n",
            "epoch 65 loss 0.3237580358982086 accuracy 0.129\n",
            "epoch 66 loss 0.32372331619262695 accuracy 0.13\n",
            "epoch 67 loss 0.32368746399879456 accuracy 0.1305714285714286\n",
            "epoch 68 loss 0.32365089654922485 accuracy 0.13128571428571428\n",
            "epoch 69 loss 0.3236141800880432 accuracy 0.13071428571428573\n",
            "epoch 70 loss 0.3235778510570526 accuracy 0.129\n",
            "epoch 71 loss 0.32354262471199036 accuracy 0.12842857142857142\n",
            "epoch 72 loss 0.3235089182853699 accuracy 0.129\n",
            "epoch 73 loss 0.32347697019577026 accuracy 0.13\n",
            "epoch 74 loss 0.32344698905944824 accuracy 0.131\n",
            "epoch 75 loss 0.32341906428337097 accuracy 0.132\n",
            "epoch 76 loss 0.3233930170536041 accuracy 0.1305714285714286\n",
            "epoch 77 loss 0.32336893677711487 accuracy 0.13114285714285714\n",
            "epoch 78 loss 0.3233466148376465 accuracy 0.13228571428571428\n",
            "epoch 79 loss 0.32332590222358704 accuracy 0.13071428571428573\n",
            "epoch 80 loss 0.32330670952796936 accuracy 0.13\n",
            "epoch 81 loss 0.32328858971595764 accuracy 0.1292857142857143\n",
            "epoch 82 loss 0.32327157258987427 accuracy 0.129\n",
            "epoch 83 loss 0.3232552707195282 accuracy 0.12885714285714286\n",
            "epoch 84 loss 0.323239803314209 accuracy 0.1277142857142857\n",
            "epoch 85 loss 0.3232247531414032 accuracy 0.12671428571428572\n",
            "epoch 86 loss 0.3232102394104004 accuracy 0.12728571428571428\n",
            "epoch 87 loss 0.32319605350494385 accuracy 0.12742857142857142\n",
            "epoch 88 loss 0.32318225502967834 accuracy 0.12628571428571428\n",
            "epoch 89 loss 0.3231687843799591 accuracy 0.12657142857142856\n",
            "epoch 90 loss 0.32315555214881897 accuracy 0.12742857142857142\n",
            "epoch 91 loss 0.3231426179409027 accuracy 0.12757142857142856\n",
            "epoch 92 loss 0.32312992215156555 accuracy 0.12785714285714286\n",
            "epoch 93 loss 0.3231174945831299 accuracy 0.1277142857142857\n",
            "epoch 94 loss 0.3231053650379181 accuracy 0.12714285714285714\n",
            "epoch 95 loss 0.3230934739112854 accuracy 0.126\n",
            "epoch 96 loss 0.3230817914009094 accuracy 0.12628571428571428\n",
            "epoch 97 loss 0.323070228099823 accuracy 0.1267142857142857\n",
            "epoch 98 loss 0.3230589032173157 accuracy 0.127\n",
            "epoch 99 loss 0.3230477273464203 accuracy 0.12628571428571428\n",
            "epoch 100 loss 0.3230365514755249 accuracy 0.12614285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = []\n",
        "test_accuracy = []\n",
        "for x, y in data_iter(batch_size, x_test, y_test):\n",
        "    state = RNN_net.begin_state(batch_size)\n",
        "    with tf.GradientTape(True) as g:\n",
        "        y_hat, state = RNN_net(tf.transpose(x, [1, 0, 2]), state)\n",
        "        y_hat_fixed = tf.squeeze(y_hat, axis=0)\n",
        "        l = loss(y, y_hat_fixed)\n",
        "    test_loss.append(l)\n",
        "    test_accuracy.append(accuracy(y, y_hat_fixed))\n",
        "    params = RNN_net.trainable_variables\n",
        "    grads = g.gradient(l, params)\n",
        "    updater.apply_gradients(zip(grads, params))\n",
        "print('test loss:', float(sum(test_loss) / len(test_loss)),\n",
        "'accuracy:', float(sum(test_accuracy) / len(test_accuracy)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "N56oB7Ij5xhi",
        "outputId": "a03cc4b5-a18a-41c1-a782-18978d8ea513"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.3281199634075165 accuracy: 0.095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_tf_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(4, 10)),\n",
        "    tf.keras.layers.SimpleRNN(units=32),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "hE63Fd5Y6KH7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_tf_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
        ")"
      ],
      "metadata": {
        "id": "564uW_jB6K-H"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN_tf_model.fit(\n",
        "    x=x_train, y=y_train,\n",
        "    batch_size=batch_size, epochs=100,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a7MmRuXa6Wve",
        "outputId": "94ed6377-7121-4446-8d4a-6f0996431e01"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.1153 - loss: 2.3273 - val_categorical_accuracy: 0.0983 - val_loss: 2.3331\n",
            "Epoch 2/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - categorical_accuracy: 0.1123 - loss: 2.3175 - val_categorical_accuracy: 0.0960 - val_loss: 2.3273\n",
            "Epoch 3/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1204 - loss: 2.3087 - val_categorical_accuracy: 0.0947 - val_loss: 2.3249\n",
            "Epoch 4/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - categorical_accuracy: 0.1204 - loss: 2.2999 - val_categorical_accuracy: 0.0920 - val_loss: 2.3237\n",
            "Epoch 5/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.1239 - loss: 2.2988 - val_categorical_accuracy: 0.0917 - val_loss: 2.3235\n",
            "Epoch 6/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - categorical_accuracy: 0.1295 - loss: 2.2929 - val_categorical_accuracy: 0.0927 - val_loss: 2.3237\n",
            "Epoch 7/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1326 - loss: 2.2909 - val_categorical_accuracy: 0.0950 - val_loss: 2.3239\n",
            "Epoch 8/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1341 - loss: 2.2890 - val_categorical_accuracy: 0.0920 - val_loss: 2.3243\n",
            "Epoch 9/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1330 - loss: 2.2881 - val_categorical_accuracy: 0.0927 - val_loss: 2.3254\n",
            "Epoch 10/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1382 - loss: 2.2862 - val_categorical_accuracy: 0.0940 - val_loss: 2.3267\n",
            "Epoch 11/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1370 - loss: 2.2840 - val_categorical_accuracy: 0.0963 - val_loss: 2.3277\n",
            "Epoch 12/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1358 - loss: 2.2852 - val_categorical_accuracy: 0.0960 - val_loss: 2.3277\n",
            "Epoch 13/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.1452 - loss: 2.2822 - val_categorical_accuracy: 0.1007 - val_loss: 2.3283\n",
            "Epoch 14/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1365 - loss: 2.2807 - val_categorical_accuracy: 0.0943 - val_loss: 2.3301\n",
            "Epoch 15/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - categorical_accuracy: 0.1354 - loss: 2.2823 - val_categorical_accuracy: 0.0977 - val_loss: 2.3298\n",
            "Epoch 16/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - categorical_accuracy: 0.1457 - loss: 2.2795 - val_categorical_accuracy: 0.0993 - val_loss: 2.3307\n",
            "Epoch 17/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - categorical_accuracy: 0.1403 - loss: 2.2790 - val_categorical_accuracy: 0.0997 - val_loss: 2.3317\n",
            "Epoch 18/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1458 - loss: 2.2775 - val_categorical_accuracy: 0.0960 - val_loss: 2.3317\n",
            "Epoch 19/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1394 - loss: 2.2771 - val_categorical_accuracy: 0.0940 - val_loss: 2.3328\n",
            "Epoch 20/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1365 - loss: 2.2816 - val_categorical_accuracy: 0.0950 - val_loss: 2.3331\n",
            "Epoch 21/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1411 - loss: 2.2804 - val_categorical_accuracy: 0.0920 - val_loss: 2.3333\n",
            "Epoch 22/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1339 - loss: 2.2802 - val_categorical_accuracy: 0.0940 - val_loss: 2.3337\n",
            "Epoch 23/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1394 - loss: 2.2810 - val_categorical_accuracy: 0.0927 - val_loss: 2.3347\n",
            "Epoch 24/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1400 - loss: 2.2761 - val_categorical_accuracy: 0.0957 - val_loss: 2.3352\n",
            "Epoch 25/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1323 - loss: 2.2770 - val_categorical_accuracy: 0.0957 - val_loss: 2.3348\n",
            "Epoch 26/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1327 - loss: 2.2774 - val_categorical_accuracy: 0.0967 - val_loss: 2.3348\n",
            "Epoch 27/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1347 - loss: 2.2745 - val_categorical_accuracy: 0.0940 - val_loss: 2.3363\n",
            "Epoch 28/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1294 - loss: 2.2779 - val_categorical_accuracy: 0.0947 - val_loss: 2.3365\n",
            "Epoch 29/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1287 - loss: 2.2811 - val_categorical_accuracy: 0.0907 - val_loss: 2.3365\n",
            "Epoch 30/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1362 - loss: 2.2793 - val_categorical_accuracy: 0.0993 - val_loss: 2.3371\n",
            "Epoch 31/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1322 - loss: 2.2751 - val_categorical_accuracy: 0.0970 - val_loss: 2.3371\n",
            "Epoch 32/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1323 - loss: 2.2812 - val_categorical_accuracy: 0.0953 - val_loss: 2.3380\n",
            "Epoch 33/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1374 - loss: 2.2779 - val_categorical_accuracy: 0.0957 - val_loss: 2.3379\n",
            "Epoch 34/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1309 - loss: 2.2768 - val_categorical_accuracy: 0.0937 - val_loss: 2.3392\n",
            "Epoch 35/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1366 - loss: 2.2744 - val_categorical_accuracy: 0.0943 - val_loss: 2.3383\n",
            "Epoch 36/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1340 - loss: 2.2748 - val_categorical_accuracy: 0.0963 - val_loss: 2.3385\n",
            "Epoch 37/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1345 - loss: 2.2711 - val_categorical_accuracy: 0.0927 - val_loss: 2.3386\n",
            "Epoch 38/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1353 - loss: 2.2759 - val_categorical_accuracy: 0.0970 - val_loss: 2.3393\n",
            "Epoch 39/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1403 - loss: 2.2754 - val_categorical_accuracy: 0.0957 - val_loss: 2.3394\n",
            "Epoch 40/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1388 - loss: 2.2725 - val_categorical_accuracy: 0.0917 - val_loss: 2.3399\n",
            "Epoch 41/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1335 - loss: 2.2754 - val_categorical_accuracy: 0.0937 - val_loss: 2.3393\n",
            "Epoch 42/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1352 - loss: 2.2744 - val_categorical_accuracy: 0.0923 - val_loss: 2.3405\n",
            "Epoch 43/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1368 - loss: 2.2753 - val_categorical_accuracy: 0.0960 - val_loss: 2.3406\n",
            "Epoch 44/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1379 - loss: 2.2714 - val_categorical_accuracy: 0.0923 - val_loss: 2.3407\n",
            "Epoch 45/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1444 - loss: 2.2721 - val_categorical_accuracy: 0.0970 - val_loss: 2.3402\n",
            "Epoch 46/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1386 - loss: 2.2705 - val_categorical_accuracy: 0.0903 - val_loss: 2.3405\n",
            "Epoch 47/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1313 - loss: 2.2747 - val_categorical_accuracy: 0.0963 - val_loss: 2.3410\n",
            "Epoch 48/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1432 - loss: 2.2663 - val_categorical_accuracy: 0.0943 - val_loss: 2.3412\n",
            "Epoch 49/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1345 - loss: 2.2722 - val_categorical_accuracy: 0.0877 - val_loss: 2.3420\n",
            "Epoch 50/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - categorical_accuracy: 0.1400 - loss: 2.2697 - val_categorical_accuracy: 0.0977 - val_loss: 2.3416\n",
            "Epoch 51/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1392 - loss: 2.2708 - val_categorical_accuracy: 0.0903 - val_loss: 2.3418\n",
            "Epoch 52/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1409 - loss: 2.2724 - val_categorical_accuracy: 0.0913 - val_loss: 2.3429\n",
            "Epoch 53/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1396 - loss: 2.2723 - val_categorical_accuracy: 0.0970 - val_loss: 2.3418\n",
            "Epoch 54/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - categorical_accuracy: 0.1410 - loss: 2.2674 - val_categorical_accuracy: 0.0917 - val_loss: 2.3423\n",
            "Epoch 55/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1376 - loss: 2.2704 - val_categorical_accuracy: 0.0970 - val_loss: 2.3419\n",
            "Epoch 56/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1373 - loss: 2.2669 - val_categorical_accuracy: 0.0983 - val_loss: 2.3429\n",
            "Epoch 57/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - categorical_accuracy: 0.1409 - loss: 2.2711 - val_categorical_accuracy: 0.0923 - val_loss: 2.3428\n",
            "Epoch 58/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1378 - loss: 2.2701 - val_categorical_accuracy: 0.0887 - val_loss: 2.3437\n",
            "Epoch 59/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1368 - loss: 2.2683 - val_categorical_accuracy: 0.0937 - val_loss: 2.3436\n",
            "Epoch 60/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1478 - loss: 2.2658 - val_categorical_accuracy: 0.0937 - val_loss: 2.3433\n",
            "Epoch 61/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1403 - loss: 2.2647 - val_categorical_accuracy: 0.0927 - val_loss: 2.3443\n",
            "Epoch 62/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1426 - loss: 2.2633 - val_categorical_accuracy: 0.0913 - val_loss: 2.3439\n",
            "Epoch 63/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1360 - loss: 2.2655 - val_categorical_accuracy: 0.0917 - val_loss: 2.3450\n",
            "Epoch 64/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1432 - loss: 2.2655 - val_categorical_accuracy: 0.0940 - val_loss: 2.3443\n",
            "Epoch 65/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1502 - loss: 2.2674 - val_categorical_accuracy: 0.0950 - val_loss: 2.3442\n",
            "Epoch 66/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1348 - loss: 2.2670 - val_categorical_accuracy: 0.0933 - val_loss: 2.3449\n",
            "Epoch 67/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1445 - loss: 2.2620 - val_categorical_accuracy: 0.0877 - val_loss: 2.3459\n",
            "Epoch 68/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1458 - loss: 2.2644 - val_categorical_accuracy: 0.0920 - val_loss: 2.3461\n",
            "Epoch 69/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1455 - loss: 2.2642 - val_categorical_accuracy: 0.0903 - val_loss: 2.3459\n",
            "Epoch 70/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1399 - loss: 2.2674 - val_categorical_accuracy: 0.0917 - val_loss: 2.3464\n",
            "Epoch 71/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1406 - loss: 2.2613 - val_categorical_accuracy: 0.0900 - val_loss: 2.3479\n",
            "Epoch 72/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1426 - loss: 2.2649 - val_categorical_accuracy: 0.0910 - val_loss: 2.3477\n",
            "Epoch 73/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1486 - loss: 2.2601 - val_categorical_accuracy: 0.0930 - val_loss: 2.3466\n",
            "Epoch 74/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1475 - loss: 2.2580 - val_categorical_accuracy: 0.0900 - val_loss: 2.3486\n",
            "Epoch 75/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1458 - loss: 2.2602 - val_categorical_accuracy: 0.0883 - val_loss: 2.3469\n",
            "Epoch 76/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1489 - loss: 2.2613 - val_categorical_accuracy: 0.0843 - val_loss: 2.3484\n",
            "Epoch 77/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1536 - loss: 2.2536 - val_categorical_accuracy: 0.0883 - val_loss: 2.3477\n",
            "Epoch 78/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1543 - loss: 2.2551 - val_categorical_accuracy: 0.0883 - val_loss: 2.3490\n",
            "Epoch 79/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1590 - loss: 2.2566 - val_categorical_accuracy: 0.0897 - val_loss: 2.3486\n",
            "Epoch 80/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1399 - loss: 2.2628 - val_categorical_accuracy: 0.0920 - val_loss: 2.3491\n",
            "Epoch 81/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1573 - loss: 2.2614 - val_categorical_accuracy: 0.0890 - val_loss: 2.3492\n",
            "Epoch 82/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1556 - loss: 2.2528 - val_categorical_accuracy: 0.0913 - val_loss: 2.3502\n",
            "Epoch 83/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1496 - loss: 2.2592 - val_categorical_accuracy: 0.0873 - val_loss: 2.3503\n",
            "Epoch 84/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1534 - loss: 2.2583 - val_categorical_accuracy: 0.0910 - val_loss: 2.3508\n",
            "Epoch 85/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1501 - loss: 2.2523 - val_categorical_accuracy: 0.0880 - val_loss: 2.3516\n",
            "Epoch 86/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1561 - loss: 2.2546 - val_categorical_accuracy: 0.0857 - val_loss: 2.3514\n",
            "Epoch 87/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1534 - loss: 2.2561 - val_categorical_accuracy: 0.0867 - val_loss: 2.3518\n",
            "Epoch 88/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1539 - loss: 2.2544 - val_categorical_accuracy: 0.0913 - val_loss: 2.3511\n",
            "Epoch 89/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1575 - loss: 2.2552 - val_categorical_accuracy: 0.0907 - val_loss: 2.3515\n",
            "Epoch 90/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1633 - loss: 2.2482 - val_categorical_accuracy: 0.0860 - val_loss: 2.3518\n",
            "Epoch 91/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1587 - loss: 2.2474 - val_categorical_accuracy: 0.0927 - val_loss: 2.3525\n",
            "Epoch 92/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1577 - loss: 2.2538 - val_categorical_accuracy: 0.0893 - val_loss: 2.3530\n",
            "Epoch 93/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1545 - loss: 2.2545 - val_categorical_accuracy: 0.0913 - val_loss: 2.3545\n",
            "Epoch 94/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1625 - loss: 2.2463 - val_categorical_accuracy: 0.0890 - val_loss: 2.3545\n",
            "Epoch 95/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1533 - loss: 2.2518 - val_categorical_accuracy: 0.0900 - val_loss: 2.3546\n",
            "Epoch 96/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1579 - loss: 2.2515 - val_categorical_accuracy: 0.0877 - val_loss: 2.3550\n",
            "Epoch 97/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1520 - loss: 2.2469 - val_categorical_accuracy: 0.0923 - val_loss: 2.3551\n",
            "Epoch 98/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1554 - loss: 2.2481 - val_categorical_accuracy: 0.0893 - val_loss: 2.3554\n",
            "Epoch 99/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1593 - loss: 2.2470 - val_categorical_accuracy: 0.0897 - val_loss: 2.3566\n",
            "Epoch 100/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1599 - loss: 2.2429 - val_categorical_accuracy: 0.0870 - val_loss: 2.3559\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x784015f052e0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_tf_model = tf.keras.Sequential()\n",
        "LSTM_tf_model.add(tf.keras.layers.Input(shape=(4, 10)))\n",
        "LSTM_tf_model.add(tf.keras.layers.LSTM(units=32))\n",
        "LSTM_tf_model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "Sf6TxrJ96gFH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_tf_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
        ")"
      ],
      "metadata": {
        "id": "07r1tFlr6hdJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_tf_model.fit(\n",
        "    x=x_train, y=y_train,\n",
        "    batch_size=batch_size, epochs=100,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w6XSdeiq6jUr",
        "outputId": "c8b8ff71-a696-4a42-f25a-7cb8dbd78757"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - categorical_accuracy: 0.1065 - loss: 2.3043 - val_categorical_accuracy: 0.0993 - val_loss: 2.3056\n",
            "Epoch 2/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1123 - loss: 2.3010 - val_categorical_accuracy: 0.1000 - val_loss: 2.3069\n",
            "Epoch 3/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1150 - loss: 2.2999 - val_categorical_accuracy: 0.0930 - val_loss: 2.3073\n",
            "Epoch 4/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1131 - loss: 2.2995 - val_categorical_accuracy: 0.0953 - val_loss: 2.3079\n",
            "Epoch 5/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1111 - loss: 2.2988 - val_categorical_accuracy: 0.0950 - val_loss: 2.3086\n",
            "Epoch 6/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1178 - loss: 2.2961 - val_categorical_accuracy: 0.0950 - val_loss: 2.3089\n",
            "Epoch 7/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1160 - loss: 2.2966 - val_categorical_accuracy: 0.0960 - val_loss: 2.3095\n",
            "Epoch 8/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1175 - loss: 2.2966 - val_categorical_accuracy: 0.0930 - val_loss: 2.3100\n",
            "Epoch 9/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1191 - loss: 2.2962 - val_categorical_accuracy: 0.0953 - val_loss: 2.3103\n",
            "Epoch 10/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1215 - loss: 2.2956 - val_categorical_accuracy: 0.0943 - val_loss: 2.3114\n",
            "Epoch 11/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1188 - loss: 2.2940 - val_categorical_accuracy: 0.0953 - val_loss: 2.3122\n",
            "Epoch 12/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1151 - loss: 2.2973 - val_categorical_accuracy: 0.0953 - val_loss: 2.3126\n",
            "Epoch 13/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1199 - loss: 2.2946 - val_categorical_accuracy: 0.0953 - val_loss: 2.3140\n",
            "Epoch 14/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1202 - loss: 2.2954 - val_categorical_accuracy: 0.0973 - val_loss: 2.3144\n",
            "Epoch 15/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1170 - loss: 2.2911 - val_categorical_accuracy: 0.0963 - val_loss: 2.3153\n",
            "Epoch 16/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1204 - loss: 2.2920 - val_categorical_accuracy: 0.0930 - val_loss: 2.3160\n",
            "Epoch 17/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1313 - loss: 2.2913 - val_categorical_accuracy: 0.0963 - val_loss: 2.3168\n",
            "Epoch 18/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1265 - loss: 2.2883 - val_categorical_accuracy: 0.0960 - val_loss: 2.3174\n",
            "Epoch 19/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1277 - loss: 2.2896 - val_categorical_accuracy: 0.0973 - val_loss: 2.3178\n",
            "Epoch 20/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1302 - loss: 2.2879 - val_categorical_accuracy: 0.0950 - val_loss: 2.3187\n",
            "Epoch 21/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1299 - loss: 2.2859 - val_categorical_accuracy: 0.0967 - val_loss: 2.3198\n",
            "Epoch 22/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1307 - loss: 2.2898 - val_categorical_accuracy: 0.0950 - val_loss: 2.3204\n",
            "Epoch 23/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1301 - loss: 2.2845 - val_categorical_accuracy: 0.0973 - val_loss: 2.3214\n",
            "Epoch 24/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1310 - loss: 2.2866 - val_categorical_accuracy: 0.0983 - val_loss: 2.3219\n",
            "Epoch 25/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1268 - loss: 2.2879 - val_categorical_accuracy: 0.0967 - val_loss: 2.3224\n",
            "Epoch 26/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1242 - loss: 2.2844 - val_categorical_accuracy: 0.0983 - val_loss: 2.3233\n",
            "Epoch 27/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1232 - loss: 2.2871 - val_categorical_accuracy: 0.0993 - val_loss: 2.3237\n",
            "Epoch 28/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1297 - loss: 2.2869 - val_categorical_accuracy: 0.0970 - val_loss: 2.3245\n",
            "Epoch 29/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1344 - loss: 2.2839 - val_categorical_accuracy: 0.0943 - val_loss: 2.3253\n",
            "Epoch 30/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1263 - loss: 2.2861 - val_categorical_accuracy: 0.0980 - val_loss: 2.3261\n",
            "Epoch 31/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1305 - loss: 2.2826 - val_categorical_accuracy: 0.0967 - val_loss: 2.3268\n",
            "Epoch 32/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1312 - loss: 2.2851 - val_categorical_accuracy: 0.0970 - val_loss: 2.3279\n",
            "Epoch 33/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1324 - loss: 2.2846 - val_categorical_accuracy: 0.0957 - val_loss: 2.3282\n",
            "Epoch 34/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1389 - loss: 2.2778 - val_categorical_accuracy: 0.0970 - val_loss: 2.3290\n",
            "Epoch 35/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1370 - loss: 2.2789 - val_categorical_accuracy: 0.0980 - val_loss: 2.3299\n",
            "Epoch 36/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1399 - loss: 2.2792 - val_categorical_accuracy: 0.0940 - val_loss: 2.3310\n",
            "Epoch 37/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1388 - loss: 2.2771 - val_categorical_accuracy: 0.0953 - val_loss: 2.3307\n",
            "Epoch 38/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - categorical_accuracy: 0.1388 - loss: 2.2779 - val_categorical_accuracy: 0.0927 - val_loss: 2.3326\n",
            "Epoch 39/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - categorical_accuracy: 0.1361 - loss: 2.2770 - val_categorical_accuracy: 0.0933 - val_loss: 2.3331\n",
            "Epoch 40/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - categorical_accuracy: 0.1353 - loss: 2.2782 - val_categorical_accuracy: 0.0900 - val_loss: 2.3343\n",
            "Epoch 41/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - categorical_accuracy: 0.1406 - loss: 2.2781 - val_categorical_accuracy: 0.0917 - val_loss: 2.3348\n",
            "Epoch 42/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.1378 - loss: 2.2725 - val_categorical_accuracy: 0.0887 - val_loss: 2.3365\n",
            "Epoch 43/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1443 - loss: 2.2754 - val_categorical_accuracy: 0.0873 - val_loss: 2.3363\n",
            "Epoch 44/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1487 - loss: 2.2734 - val_categorical_accuracy: 0.0867 - val_loss: 2.3380\n",
            "Epoch 45/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1430 - loss: 2.2678 - val_categorical_accuracy: 0.0880 - val_loss: 2.3402\n",
            "Epoch 46/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1491 - loss: 2.2666 - val_categorical_accuracy: 0.0887 - val_loss: 2.3397\n",
            "Epoch 47/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1491 - loss: 2.2686 - val_categorical_accuracy: 0.0847 - val_loss: 2.3413\n",
            "Epoch 48/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1508 - loss: 2.2664 - val_categorical_accuracy: 0.0873 - val_loss: 2.3429\n",
            "Epoch 49/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1521 - loss: 2.2646 - val_categorical_accuracy: 0.0887 - val_loss: 2.3442\n",
            "Epoch 50/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1502 - loss: 2.2669 - val_categorical_accuracy: 0.0913 - val_loss: 2.3441\n",
            "Epoch 51/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1599 - loss: 2.2578 - val_categorical_accuracy: 0.0913 - val_loss: 2.3462\n",
            "Epoch 52/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1597 - loss: 2.2612 - val_categorical_accuracy: 0.0897 - val_loss: 2.3467\n",
            "Epoch 53/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1582 - loss: 2.2567 - val_categorical_accuracy: 0.0880 - val_loss: 2.3475\n",
            "Epoch 54/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1557 - loss: 2.2585 - val_categorical_accuracy: 0.0903 - val_loss: 2.3485\n",
            "Epoch 55/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1717 - loss: 2.2556 - val_categorical_accuracy: 0.0890 - val_loss: 2.3504\n",
            "Epoch 56/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1657 - loss: 2.2533 - val_categorical_accuracy: 0.0937 - val_loss: 2.3513\n",
            "Epoch 57/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1657 - loss: 2.2530 - val_categorical_accuracy: 0.0923 - val_loss: 2.3528\n",
            "Epoch 58/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1607 - loss: 2.2507 - val_categorical_accuracy: 0.0923 - val_loss: 2.3538\n",
            "Epoch 59/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1742 - loss: 2.2467 - val_categorical_accuracy: 0.0947 - val_loss: 2.3542\n",
            "Epoch 60/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1620 - loss: 2.2505 - val_categorical_accuracy: 0.0933 - val_loss: 2.3554\n",
            "Epoch 61/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1699 - loss: 2.2474 - val_categorical_accuracy: 0.0920 - val_loss: 2.3573\n",
            "Epoch 62/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1702 - loss: 2.2478 - val_categorical_accuracy: 0.0953 - val_loss: 2.3575\n",
            "Epoch 63/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1735 - loss: 2.2431 - val_categorical_accuracy: 0.0947 - val_loss: 2.3589\n",
            "Epoch 64/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1781 - loss: 2.2458 - val_categorical_accuracy: 0.0963 - val_loss: 2.3602\n",
            "Epoch 65/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1762 - loss: 2.2417 - val_categorical_accuracy: 0.0953 - val_loss: 2.3612\n",
            "Epoch 66/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1699 - loss: 2.2417 - val_categorical_accuracy: 0.0963 - val_loss: 2.3627\n",
            "Epoch 67/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - categorical_accuracy: 0.1774 - loss: 2.2393 - val_categorical_accuracy: 0.0960 - val_loss: 2.3626\n",
            "Epoch 68/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1785 - loss: 2.2385 - val_categorical_accuracy: 0.0980 - val_loss: 2.3640\n",
            "Epoch 69/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1804 - loss: 2.2339 - val_categorical_accuracy: 0.0990 - val_loss: 2.3658\n",
            "Epoch 70/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1693 - loss: 2.2394 - val_categorical_accuracy: 0.0987 - val_loss: 2.3666\n",
            "Epoch 71/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1831 - loss: 2.2279 - val_categorical_accuracy: 0.0977 - val_loss: 2.3689\n",
            "Epoch 72/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1836 - loss: 2.2305 - val_categorical_accuracy: 0.1013 - val_loss: 2.3686\n",
            "Epoch 73/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1817 - loss: 2.2328 - val_categorical_accuracy: 0.1000 - val_loss: 2.3703\n",
            "Epoch 74/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1898 - loss: 2.2231 - val_categorical_accuracy: 0.0980 - val_loss: 2.3710\n",
            "Epoch 75/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1865 - loss: 2.2262 - val_categorical_accuracy: 0.0953 - val_loss: 2.3719\n",
            "Epoch 76/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1766 - loss: 2.2246 - val_categorical_accuracy: 0.0970 - val_loss: 2.3746\n",
            "Epoch 77/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1845 - loss: 2.2289 - val_categorical_accuracy: 0.1020 - val_loss: 2.3737\n",
            "Epoch 78/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1820 - loss: 2.2242 - val_categorical_accuracy: 0.0977 - val_loss: 2.3760\n",
            "Epoch 79/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - categorical_accuracy: 0.1918 - loss: 2.2158 - val_categorical_accuracy: 0.0993 - val_loss: 2.3767\n",
            "Epoch 80/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - categorical_accuracy: 0.1898 - loss: 2.2201 - val_categorical_accuracy: 0.1000 - val_loss: 2.3777\n",
            "Epoch 81/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - categorical_accuracy: 0.1788 - loss: 2.2234 - val_categorical_accuracy: 0.0997 - val_loss: 2.3784\n",
            "Epoch 82/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - categorical_accuracy: 0.1793 - loss: 2.2128 - val_categorical_accuracy: 0.0973 - val_loss: 2.3800\n",
            "Epoch 83/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - categorical_accuracy: 0.1816 - loss: 2.2129 - val_categorical_accuracy: 0.0963 - val_loss: 2.3813\n",
            "Epoch 84/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1876 - loss: 2.2109 - val_categorical_accuracy: 0.1010 - val_loss: 2.3817\n",
            "Epoch 85/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1842 - loss: 2.2184 - val_categorical_accuracy: 0.0963 - val_loss: 2.3836\n",
            "Epoch 86/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1867 - loss: 2.2048 - val_categorical_accuracy: 0.0953 - val_loss: 2.3839\n",
            "Epoch 87/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1879 - loss: 2.2073 - val_categorical_accuracy: 0.0990 - val_loss: 2.3853\n",
            "Epoch 88/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1795 - loss: 2.2103 - val_categorical_accuracy: 0.0980 - val_loss: 2.3869\n",
            "Epoch 89/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1838 - loss: 2.2042 - val_categorical_accuracy: 0.0977 - val_loss: 2.3865\n",
            "Epoch 90/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1870 - loss: 2.2070 - val_categorical_accuracy: 0.0983 - val_loss: 2.3888\n",
            "Epoch 91/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1854 - loss: 2.2089 - val_categorical_accuracy: 0.1000 - val_loss: 2.3898\n",
            "Epoch 92/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1864 - loss: 2.2081 - val_categorical_accuracy: 0.0990 - val_loss: 2.3901\n",
            "Epoch 93/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1933 - loss: 2.1984 - val_categorical_accuracy: 0.0993 - val_loss: 2.3925\n",
            "Epoch 94/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1911 - loss: 2.2053 - val_categorical_accuracy: 0.1000 - val_loss: 2.3923\n",
            "Epoch 95/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1916 - loss: 2.2052 - val_categorical_accuracy: 0.1007 - val_loss: 2.3937\n",
            "Epoch 96/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1946 - loss: 2.1989 - val_categorical_accuracy: 0.0980 - val_loss: 2.3949\n",
            "Epoch 97/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1953 - loss: 2.1932 - val_categorical_accuracy: 0.0980 - val_loss: 2.3964\n",
            "Epoch 98/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.1921 - loss: 2.1941 - val_categorical_accuracy: 0.0993 - val_loss: 2.3972\n",
            "Epoch 99/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1932 - loss: 2.1889 - val_categorical_accuracy: 0.0987 - val_loss: 2.3975\n",
            "Epoch 100/100\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - categorical_accuracy: 0.1928 - loss: 2.1967 - val_categorical_accuracy: 0.0997 - val_loss: 2.3993\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7840216e0e60>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}